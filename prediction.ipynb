{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"pruned_offline_workload.CSV\")\n",
    "dev = pd.read_csv(\"online_workload_B.csv\")\n",
    "target = pd.read_csv(\"online_workload_C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation and normalisation\n",
    "\n",
    "workload_id = [df.workload_id[i] for i in range (18349)]\n",
    "k1 = [df.k1[i] for i in range (18349)]\n",
    "k2 = [df.k2[i] for i in range (18349)]\n",
    "k3 = [df.k3[i] for i in range (18349)]\n",
    "k4 = [df.k4[i] for i in range (18349)]\n",
    "k5 = [df.k5[i] for i in range (18349)]\n",
    "k6 = [df.k6[i] for i in range (18349)]\n",
    "k7 = [df.k7[i] for i in range (18349)]\n",
    "k8 = [df.k8[i] for i in range (18349)]\n",
    "s1 = [df.s1[i] for i in range (18349)]\n",
    "s2 = [df.s2[i] for i in range (18349)]\n",
    "s3 = [df.s3[i] for i in range (18349)]\n",
    "s4 = [df.s4[i] for i in range (18349)]\n",
    "m1 = [df.m1[i]/1000000000 for i in range (18349)]\n",
    "m2 = [df.m2[i]/100000000 for i in range (18349)]\n",
    "m3 = [df.m3[i] * 100 for i in range (18349)]\n",
    "latency = [df.latency[i] for i in range (18349)]\n",
    "dev_m1 = [dev.m1[i]/1000000000 for i in range (600)]\n",
    "dev_m2 = [dev.m2[i]/100000000 for i in range (600)]\n",
    "dev_m3 = [dev.m3[i] * 100 for i in range (600)]\n",
    "dev_latency = [dev.latency[i] for i in range (600)]\n",
    "target_m1 = [target.m1[i]/1000000000 for i in range (500)]\n",
    "target_m2 = [target.m2[i]/100000000 for i in range (500)]\n",
    "target_m3= [target.m3[i] * 100 for i in range (500)]\n",
    "target_latency = [target.latency[i] for i in range (500)]\n",
    "target_workload =[target.workload_id for i in range(500)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workload Mapping\n",
    "from scipy.spatial import distance\n",
    "mapped_workloads = []\n",
    "for i in range(18349):\n",
    "    min_avg=9999999\n",
    "    index = -1\n",
    "    for j in range(500):\n",
    "        d1 = distance.euclidean(target_m1[j], m1[i])\n",
    "        d2 = distance.euclidean(target_m2[j], m2[i])\n",
    "        d3 = distance.euclidean(target_m3[j], m3[i])\n",
    "        if (d1 + d2 + d3)/3 < min_avg:\n",
    "            min_avg = (d1 + d2 + d3)/3\n",
    "            index = j\n",
    "    mapped_workloads.append(index)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [(m1[i], m2[i], m3[i]) for i in range (18349)]\n",
    "X_test = [(target_m1[i], target_m2[i], target_m3[i]) for i in range (500)]\n",
    "X_dev = [(dev_m1[i], dev_m2[i], dev_m3[i]) for i in range (600)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyGPs\n",
    "import numpy as np\n",
    "model = pyGPs.GPR()      # specify model (GP regression)\n",
    "model.getPosterior(np.array(X_train), np.array(latency)) # fit default model (mean zero & rbf kernel) with data\n",
    "model.optimize(np.array(X_train), np.array(latency))     # optimize hyperparamters (default optimizer: single run minimize)\n",
    "model.predict(np.array(X_test))         # predict test cases\n",
    "model.plot()             # and plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.gaussian_process as gp\n",
    "kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
    "model.fit(X_train, latency)\n",
    "params = model.kernel_.get_params()\n",
    "y_pred, std = model.predict(X_test, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.40319083334, 36.401125, 22.799525, 37.9592550002, 34.2307775, 26.812803333600005, 12.935120000000001, 42.557264999999994, 24.290193333399998, 37.387489166659996, 34.839858333799995, 15.538705000000002, 34.15193000000001, 17.403772500080002, 8.739505, 386.63381, 8.856375, 343.37359499999997, 101.19203, 71.52809500000001, 54.83665499999999, 72.2965083334, 10.2497683334, 78.2180225004, 39.62437833399999, 47.130456666680004, 29.1843316664, 28.72006, 50.60391166666001, 30.5108483334, 25.813874999986666, 45.499275, 35.92258833340001, 25.508121666399997, 40.6385866666, 30.562540000000002, 62.08883500000002, 6.2338249999999995, 16.34196500048, 13.0548125, 39.599068333400005, 20.22753333334, 12.295225000000002, 152.68102833360004, 13.734585833259999, 324.7796, 110.788786667, 133.367605, 81.50443499999999, 135.549345, 9.9537841667, 78.55701, 23.92136, 61.35585000000001, 36.91566, 22.534625833339998, 12.186819999999999, 21.418305000600004, 14.689550000000002, 38.889775, 37.72936, 30.3102866668, 34.961884999999995, 22.7398216667, 45.6405033334, 34.697105, 44.597158333399996, 14.530751666719999, 31.41385333333334, 26.264183333400002, 10.854158333400001, 174.31349, 16.117926666720003, 342.415215, 113.39330499999998, 119.71985, 31.342929999999996, 62.651925000000006, 15.008866666600003, 45.76449166680001, 27.55955, 32.990765, 22.2832966667, 7.55615166666, 22.925370000020003, 24.50877999996, 22.762014999999998, 67.0503533332, 32.446785, 33.00838, 13.593383333600002, 38.067138333399996, 100.79482166599999, 15.772295833320001, 20.071427500059997, 17.85731291666, 24.1907166668, 21.66148583326, 25.699685, 135.48857500000003]\n"
     ]
    }
   ],
   "source": [
    "predicted_latency = []\n",
    "for i in range (0, len(y_pred), 5):\n",
    "    avg = (y_pred[i]+y_pred[i+1]+y_pred[i+2]+y_pred[i+3]+y_pred[i+4])/5\n",
    "    predicted_latency.append(avg)\n",
    "print(predicted_latency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "rows = zip(predicted_latency)\n",
    "with open('temp.CSV', mode='w') as csv_file:\n",
    "    wr = csv.writer(csv_file, quoting=csv.QUOTE_ALL)\n",
    "    for row in rows:\n",
    "        wr.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "work=[workload_id[mapped_workloads[i]] for i in range(100)]\n",
    "rows = zip(work)\n",
    "with open('temp1.CSV', mode='w') as csv_file:\n",
    "    wr = csv.writer(csv_file, quoting=csv.QUOTE_ALL)\n",
    "    for row in rows:\n",
    "        wr.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14135\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import seaborn as sns\n",
    "RandomForest = RandomForestRegressor()\n",
    "RandomForest.fit(X_train, latency)\n",
    "y_pred = RandomForest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"The function to predict.\"\"\"\n",
    "    return x * np.sin(x)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  First the noiseless case\n",
    "X = np.atleast_2d([1., 3., 5., 6., 7., 8.]).T\n",
    "\n",
    "# Observations\n",
    "y = f(X).ravel()\n",
    "\n",
    "# Mesh the input space for evaluations of the real function, the prediction and\n",
    "# its MSE\n",
    "x = np.atleast_2d(np.linspace(0, 10, 1000)).T\n",
    "\n",
    "# Instantiate a Gaussian Process model\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "gp.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis (ask for MSE as well)\n",
    "y_pred, sigma = gp.predict(x, return_std=True)\n",
    "\n",
    "# Plot the function, the prediction and the 95% confidence interval based on\n",
    "# the MSE\n",
    "plt.figure()\n",
    "plt.plot(x, f(x), 'r:', label=r'$f(x) = x\\,\\sin(x)$')\n",
    "plt.plot(X, y, 'r.', markersize=10, label='Observations')\n",
    "plt.plot(x, y_pred, 'b-', label='Prediction')\n",
    "plt.fill(np.concatenate([x, x[::-1]]),\n",
    "         np.concatenate([y_pred - 1.9600 * sigma,\n",
    "                        (y_pred + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# now the noisy case\n",
    "X = np.linspace(0.1, 9.9, 20)\n",
    "X = np.atleast_2d(X).T\n",
    "\n",
    "# Observations and noise\n",
    "y = f(X).ravel()\n",
    "dy = 0.5 + 1.0 * np.random.random(y.shape)\n",
    "noise = np.random.normal(0, dy)\n",
    "y += noise\n",
    "\n",
    "# Instantiate a Gaussian Process model\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=dy ** 2,\n",
    "                              n_restarts_optimizer=10)\n",
    "\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "gp.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis (ask for MSE as well)\n",
    "y_pred, sigma = gp.predict(x, return_std=True)\n",
    "\n",
    "# Plot the function, the prediction and the 95% confidence interval based on\n",
    "# the MSE\n",
    "plt.figure()\n",
    "plt.plot(x, f(x), 'r:', label=r'$f(x) = x\\,\\sin(x)$')\n",
    "plt.errorbar(X.ravel(), y, dy, fmt='r.', markersize=10, label='Observations')\n",
    "plt.plot(x, y_pred, 'b-', label='Prediction')\n",
    "plt.fill(np.concatenate([x, x[::-1]]),\n",
    "         np.concatenate([y_pred - 1.9600 * sigma,\n",
    "                        (y_pred + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "\n",
    "rbf = ConstantKernel(1.0) * RBF(length_scale=1.0)\n",
    "gpr = GaussianProcessRegressor(kernel=rbf, alpha=noise**2)\n",
    "\n",
    "# Reuse training data from previous 1D example\n",
    "gpr.fit(X_train, Y_train)\n",
    "\n",
    "# Compute posterior predictive mean and covariance\n",
    "mu_s, cov_s = gpr.predict(X, return_cov=True)\n",
    "\n",
    "# Obtain optimized kernel parameters\n",
    "l = gpr.kernel_.k2.get_params()['length_scale']\n",
    "sigma_f = np.sqrt(gpr.kernel_.k1.get_params()['constant_value'])\n",
    "\n",
    "# Compare with previous results\n",
    "assert(np.isclose(l_opt, l))\n",
    "assert(np.isclose(sigma_f_opt, sigma_f))\n",
    "\n",
    "# Plot the results\n",
    "plot_gp(mu_s, cov_s, X, X_train=X_train, Y_train=Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
